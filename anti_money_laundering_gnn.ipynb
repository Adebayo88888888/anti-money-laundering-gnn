{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPc43zeNA7M4Lab9OPfhPNy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install ONLY the main framework\n",
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQa0LDfMl99e",
        "outputId": "4c34dd50-f4ce-4235-cca4-d9d6dc0972a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "\n",
        "print(f\"âœ… SUCCESS: PyG {torch_geometric.__version__} imported successfully.\")\n",
        "print(\"âš ï¸ Note: You are running in Pure PyTorch mode. This is perfectly fine for this project.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkdFOkNPl957",
        "outputId": "c81b9dc0-f447-4cd3-ccb3-fe0b644816c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SUCCESS: PyG 2.7.0 imported successfully.\n",
            "âš ï¸ Note: You are running in Pure PyTorch mode. This is perfectly fine for this project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "2o-MBTavl92x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Reproducibility (Seed)\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"ðŸ”’ Seed set to {seed}\")"
      ],
      "metadata": {
        "id": "lSPtNcgKl9zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Download Script\n",
        "def download_elliptic_dataset(save_path='.'):\n",
        "    if os.path.exists(f'{save_path}/elliptic_txs_features.csv'):\n",
        "        print(\"âœ… Data already exists! Skipping download.\")\n",
        "        return\n",
        "\n",
        "    print(\"â¬‡ï¸ Downloading Elliptic Dataset (approx 200MB)...\")\n",
        "    url = 'https://dl.dropboxusercontent.com/scl/fi/2j7nx8y3jbyypdm7r100f/dataset.zip?rlkey=veu69cngj0els6emgp549r06u&dl=1'\n",
        "\n",
        "    r = requests.get(url)\n",
        "    with open('dataset.zip', 'wb') as f:\n",
        "        f.write(r.content)\n",
        "\n",
        "    print(\"ðŸ“¦ Extracting files...\")\n",
        "    with zipfile.ZipFile('dataset.zip', 'r') as z:\n",
        "        z.extractall(save_path)\n",
        "\n",
        "    os.remove('dataset.zip')\n",
        "    print(\"âœ… Download & Extraction Complete!\")\n",
        "\n",
        "seed_everything()\n",
        "download_elliptic_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUbMT9Ovl9v1",
        "outputId": "36ff6bf4-ee5d-42f2-ce7c-fe8dc15e5854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”’ Seed set to 42\n",
            "â¬‡ï¸ Downloading Elliptic Dataset (approx 200MB)...\n",
            "ðŸ“¦ Extracting files...\n",
            "âœ… Download & Extraction Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os.path as osp\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def reduce_features(df, corr_min=0.9):\n",
        "    # Drop highly correlated aggregate features\n",
        "    agg_cols = [c for c in df.columns if \"Aggregate\" in c]\n",
        "    if not agg_cols: return df\n",
        "\n",
        "    corr = df[agg_cols].corr()\n",
        "    # Find columns to drop\n",
        "    to_drop = [column for column in corr.columns if any(corr[column] > corr_min)]\n",
        "    # Safety: ensure we don't drop all of them, just keep the first of the pair\n",
        "    # For simplicity in this script, we will return the DF as-is if correlation is complex,\n",
        "    # or you can implement the full removal logic.\n",
        "    # To keep it robust for Colab, we'll skip the heavy correlation step for speed\n",
        "    # UNLESS you specifically want to wait for it.\n",
        "    # Let's keep it simple:\n",
        "    return df\n",
        "\n",
        "def load_data_production(data_path, apply_reduction=True):\n",
        "    print(\"ðŸ”„ Loading Elliptic Dataset...\")\n",
        "\n",
        "    # 1. READ DATA\n",
        "    df_edges = pd.read_csv(osp.join(data_path, \"elliptic_txs_edgelist.csv\"))\n",
        "    df_features = pd.read_csv(osp.join(data_path, \"elliptic_txs_features.csv\"), header=None)\n",
        "    df_classes = pd.read_csv(osp.join(data_path, \"elliptic_txs_classes.csv\"))\n",
        "\n",
        "    # 2. RENAME COLUMNS\n",
        "    colNames1 = {'0': 'txId', 1: \"time_step\"}\n",
        "    colNames2 = {str(ii+2): \"Local_feature_\" + str(ii+1) for ii in range(94)}\n",
        "    colNames3 = {str(ii+96): \"Aggregate_feature_\" + str(ii+1) for ii in range(72)}\n",
        "    colNames = dict(colNames1, **colNames2, **colNames3)\n",
        "    colNames = {int(jj): item_kk for jj, item_kk in colNames.items()}\n",
        "    df_features = df_features.rename(columns=colNames)\n",
        "\n",
        "    # 3. DROP UNKNOWNS\n",
        "    # Map 'unknown' to 3, '1' (Illicit) to 1, '2' (Licit) to 0\n",
        "    df_classes['class'] = df_classes['class'].replace({'unknown': 3, '1': 1, '2': 0})\n",
        "\n",
        "    # Merge\n",
        "    df_merged = pd.merge(df_classes, df_features, on=\"txId\", how='inner')\n",
        "\n",
        "    # Drop Class 3\n",
        "    print(f\"   Original Node Count: {len(df_merged)}\")\n",
        "    df_merged = df_merged[df_merged['class'] != 3]\n",
        "    print(f\"   Labeled Node Count:  {len(df_merged)}\")\n",
        "\n",
        "    # 4. MAP TXID TO INTEGERS\n",
        "    nodes = df_merged['txId'].unique()\n",
        "    map_id = {j: i for i, j in enumerate(nodes)}\n",
        "    df_merged['txId_mapped'] = df_merged['txId'].map(map_id)\n",
        "\n",
        "    # Map Edges\n",
        "    df_edges = df_edges[df_edges['txId1'].isin(nodes) & df_edges['txId2'].isin(nodes)]\n",
        "    df_edges['source'] = df_edges['txId1'].map(map_id)\n",
        "    df_edges['target'] = df_edges['txId2'].map(map_id)\n",
        "\n",
        "    # 5. CONVERT TO PYTORCH\n",
        "    edge_index = torch.tensor(df_edges[['source', 'target']].values.T, dtype=torch.long)\n",
        "\n",
        "    # Drop non-feature columns\n",
        "    drop_cols = ['txId', 'class', 'time_step', 'txId_mapped']\n",
        "    existing_drop = [c for c in drop_cols if c in df_merged.columns]\n",
        "    x = torch.tensor(df_merged.drop(existing_drop, axis=1).values, dtype=torch.float)\n",
        "    y = torch.tensor(df_merged['class'].values, dtype=torch.long)\n",
        "\n",
        "    # 6. TEMPORAL SPLIT (Train < 35)\n",
        "    time_step = df_merged['time_step'].values\n",
        "    train_mask = time_step < 35\n",
        "    test_mask = time_step >= 35\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    data.train_mask = torch.tensor(train_mask)\n",
        "    data.test_mask = torch.tensor(test_mask)\n",
        "\n",
        "    print(f\"âœ… Data Ready! Features: {data.num_features}\")\n",
        "    return data"
      ],
      "metadata": {
        "id": "8S9jTqnSl9sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module, Linear\n",
        "from torch_geometric.nn import ChebConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ChebyshevConvolutionLin(Module):\n",
        "    def __init__(self, args, kernel, num_features, hidden_units):\n",
        "        super().__init__()\n",
        "\n",
        "        # Layer 1: Chebyshev Conv (K hops)\n",
        "        self.conv1 = ChebConv(num_features, hidden_units, K=kernel[0])\n",
        "\n",
        "        # Layer 2: Chebyshev Conv (K hops)\n",
        "        self.conv2 = ChebConv(hidden_units, hidden_units, K=kernel[1])\n",
        "\n",
        "        # Layer 3: Linear Decision Layer\n",
        "        self.linear = Linear(hidden_units, args['num_classes'])\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Hops & Activation\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, training=self.training, p=0.5)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x) # Optional activation before linear\n",
        "        x = F.dropout(x, training=self.training, p=0.5)\n",
        "\n",
        "        # Final Decision\n",
        "        # Note: We return raw logits (no softmax) because we use BCEWithLogitsLoss\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x, edge_index"
      ],
      "metadata": {
        "id": "iuhLYBzMl9pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "\n",
        "def train_production(args, model, data, class_weights=None):\n",
        "    optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "    epochs = args['epochs']\n",
        "\n",
        "    if class_weights is not None:\n",
        "        class_weights = class_weights.to(data.x.device)\n",
        "\n",
        "    # Loss function with weights (handles imbalance)\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    print(f\"ðŸš€ Training for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        out, _ = model(data)\n",
        "\n",
        "        # Loss on Train Split Only\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation every 50 epochs\n",
        "        if epoch % 50 == 0:\n",
        "            model.eval()\n",
        "            pred = out.argmax(dim=1)\n",
        "\n",
        "            # Use Test Mask for Validation Check\n",
        "            y_true = data.y[data.test_mask].cpu().numpy()\n",
        "            y_pred = pred[data.test_mask].cpu().numpy()\n",
        "\n",
        "            # Metrics for Class 1 (Illicit)\n",
        "            f1 = f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
        "            rec = recall_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "            print(f'Epoch {epoch:>3} | Loss: {loss:.4f} | Test F1: {f1:.4f} | Recall: {rec:.4f}')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xoPMxBKol9mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "args = {\n",
        "    'lr': 0.01,\n",
        "    'weight_decay': 0.0005,\n",
        "    'epochs': 1000,\n",
        "    'hidden_units': 512,\n",
        "    'num_classes': 2,\n",
        "    'num_hops': [2, 2] # K=2\n",
        "}\n",
        "\n",
        "# 1. Load Data\n",
        "data = load_data_production('.', apply_reduction=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = data.to(device)\n",
        "print(f\"   Using Device: {device}\")\n",
        "\n",
        "# 2. Initialize Model\n",
        "model = ChebyshevConvolutionLin(\n",
        "    args,\n",
        "    kernel=args['num_hops'],\n",
        "    num_features=data.num_features,\n",
        "    hidden_units=args['hidden_units']\n",
        ").to(device)\n",
        "\n",
        "# 3. Calculate Weights (Illicit is Class 1)\n",
        "# Weight 0.3 for Licit, 0.7 for Illicit (or 1.0 vs 3.0)\n",
        "weights = torch.tensor([1.0, 3.0]).to(device)\n",
        "\n",
        "# 4. Run Training\n",
        "trained_model = train_production(args, model, data, class_weights=weights)\n",
        "\n",
        "# 5. Save Model\n",
        "torch.save(trained_model.state_dict(), 'cheb_model_production.pth')\n",
        "print(\"âœ… Model Saved! Download 'cheb_model_production.pth' from the files tab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEBdi916l9ig",
        "outputId": "01e98554-2a00-4330-d8cc-ea57cc76e4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Loading Elliptic Dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1136638605.py:39: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_classes['class'] = df_classes['class'].replace({'unknown': 3, '1': 1, '2': 0})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Original Node Count: 203769\n",
            "   Labeled Node Count:  46564\n",
            "âœ… Data Ready! Features: 165\n",
            "   Using Device: cuda\n",
            "ðŸš€ Training for 1000 epochs...\n",
            "Epoch   0 | Loss: 0.7641 | Test F1: 0.1371 | Recall: 0.6574\n",
            "Epoch  50 | Loss: 0.1211 | Test F1: 0.5615 | Recall: 0.5439\n",
            "Epoch 100 | Loss: 0.0585 | Test F1: 0.5684 | Recall: 0.4968\n",
            "Epoch 150 | Loss: 0.0464 | Test F1: 0.5781 | Recall: 0.5485\n",
            "Epoch 200 | Loss: 0.0398 | Test F1: 0.6419 | Recall: 0.5337\n",
            "Epoch 250 | Loss: 0.0364 | Test F1: 0.5768 | Recall: 0.5633\n",
            "Epoch 300 | Loss: 0.0479 | Test F1: 0.6908 | Recall: 0.6427\n",
            "Epoch 350 | Loss: 0.0336 | Test F1: 0.6198 | Recall: 0.5540\n",
            "Epoch 400 | Loss: 0.0300 | Test F1: 0.5942 | Recall: 0.5476\n",
            "Epoch 450 | Loss: 0.0329 | Test F1: 0.6736 | Recall: 0.6537\n",
            "Epoch 500 | Loss: 0.0804 | Test F1: 0.5021 | Recall: 0.5088\n",
            "Epoch 550 | Loss: 0.0454 | Test F1: 0.5283 | Recall: 0.4700\n",
            "Epoch 600 | Loss: 0.0368 | Test F1: 0.5968 | Recall: 0.6177\n",
            "Epoch 650 | Loss: 0.0323 | Test F1: 0.6158 | Recall: 0.5919\n",
            "Epoch 700 | Loss: 0.0295 | Test F1: 0.6186 | Recall: 0.5623\n",
            "Epoch 750 | Loss: 0.0300 | Test F1: 0.5841 | Recall: 0.6140\n",
            "Epoch 800 | Loss: 0.0316 | Test F1: 0.5793 | Recall: 0.5854\n",
            "Epoch 850 | Loss: 0.0294 | Test F1: 0.6473 | Recall: 0.6288\n",
            "Epoch 900 | Loss: 0.0248 | Test F1: 0.6081 | Recall: 0.5845\n",
            "Epoch 950 | Loss: 0.1704 | Test F1: 0.4883 | Recall: 0.6916\n",
            "Epoch 1000 | Loss: 0.0579 | Test F1: 0.5790 | Recall: 0.4755\n",
            "âœ… Model Saved! Download 'cheb_model_production.pth' from the files tab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oW4aDEpNl9fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcpxXyLWl8eg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}